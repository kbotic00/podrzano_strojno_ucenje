{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Uvod #\n","\n","U ovoj ćete vježbi dodati ispadanje *Spotify* modelu iz prethnodne vježbe i vidjeti kako vam skupna normalizacija može omogućiti uspješno treniranje modela na teškim skupovima podataka.\n","\n","Pokrenite sljedeću ćeliju da biste započeli!"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Setup plotting\n","import matplotlib.pyplot as plt\n","plt.style.use('seaborn-v0_8-whitegrid')\n","# Set Matplotlib defaults\n","plt.rc('figure', autolayout=True)\n","plt.rc('axes', labelweight='bold', labelsize='large',\n","       titleweight='bold', titlesize=18, titlepad=10)\n","plt.rc('animation', html='html5')\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Prvo učitajte skup podataka *Spotify*."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import make_column_transformer\n","from sklearn.model_selection import GroupShuffleSplit\n","\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras import callbacks\n","\n","spotify = pd.read_csv('./input/spotify.csv')\n","\n","X = spotify.copy().dropna()\n","y = X.pop('track_popularity')\n","artists = X['track_artist']\n","\n","features_num = ['danceability', 'energy', 'key', 'loudness', 'mode',\n","                'speechiness', 'acousticness', 'instrumentalness',\n","                'liveness', 'valence', 'tempo', 'duration_ms']\n","features_cat = ['playlist_genre']\n","\n","preprocessor = make_column_transformer(\n","    (StandardScaler(), features_num),\n","    (OneHotEncoder(), features_cat),\n",")\n","\n","def group_split(X, y, group, train_size=0.75):\n","    splitter = GroupShuffleSplit(train_size=train_size)\n","    train, test = next(splitter.split(X, y, groups=group))\n","    return (X.iloc[train], X.iloc[test], y.iloc[train], y.iloc[test])\n","\n","X_train, X_valid, y_train, y_valid = group_split(X, y, artists)\n","\n","X_train = preprocessor.fit_transform(X_train)\n","X_valid = preprocessor.transform(X_valid)\n","y_train = y_train / 100\n","y_valid = y_valid / 100\n","\n","input_shape = [X_train.shape[1]]\n","print(\"Input shape: {}\".format(input_shape))"]},{"cell_type":"markdown","metadata":{},"source":["# 1) Dodajte dropout Spotify modelu\n","\n","Ovdje je posljednji model iz prethnodne vježbe. Dodajte dva ispadajuća sloja, jedan nakon sloja `Dense` sa 128 jedinica i jedan nakon sloja `Dense` sa 64 jedinice. Postavite stopu ispadanja na oba na \"0.3\"."]},{"cell_type":"code","execution_count":null,"metadata":{"lines_to_next_cell":2},"outputs":[],"source":["# YOUR CODE HERE: Add two 30% dropout layers, one after 128 and one after 64\n","model = keras.Sequential([\n","    layers.Dense(128, activation='relu', input_shape=input_shape),\n","    layers.Dense(64, activation='relu'),\n","    layers.Dense(1)\n","])\n"]},{"cell_type":"markdown","metadata":{},"source":["Sada pokrenite ovu sljedeću ćeliju da uvježbate model i vidite učinak dodavanja ispadanja."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.compile(\n","    optimizer='adam',\n","    loss='mae',\n",")\n","history = model.fit(\n","    X_train, y_train,\n","    validation_data=(X_valid, y_valid),\n","    batch_size=512,\n","    epochs=50,\n","    verbose=0,\n",")\n","history_df = pd.DataFrame(history.history)\n","history_df.loc[:, ['loss', 'val_loss']].plot()\n","print(\"Minimum Validation Loss: {:0.4f}\".format(history_df['val_loss'].min()))"]},{"cell_type":"markdown","metadata":{},"source":["# 2) Procijenite odustajanje\n","\n","Prisjetite se da je ovaj model imao tendenciju pretjeranog prilagođavanja podataka oko epohe 5. Je li se činilo da dodavanje ispadanja ovaj put pomaže u sprječavanju pretjeranog prilagođavanja?"]},{"cell_type":"markdown","metadata":{},"source":["Sada ćemo promijeniti temu da istražimo kako serijska normalizacija može riješiti probleme u obuci.\n","\n","Učitajte skup podataka *Concrete*. Ovaj put nećemo raditi nikakvu standardizaciju. To će učinak normalizacije serije učiniti puno očiglednijim."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","concrete = pd.read_csv('./input/concrete.csv')\n","df = concrete.copy()\n","\n","df_train = df.sample(frac=0.7, random_state=0)\n","df_valid = df.drop(df_train.index)\n","\n","X_train = df_train.drop('CompressiveStrength', axis=1)\n","X_valid = df_valid.drop('CompressiveStrength', axis=1)\n","y_train = df_train['CompressiveStrength']\n","y_valid = df_valid['CompressiveStrength']\n","\n","input_shape = [X_train.shape[1]]"]},{"cell_type":"markdown","metadata":{},"source":["Pokrenite sljedeću ćeliju kako biste uvježbali mrežu na nestandardiziranim *Concrete* podacima."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = keras.Sequential([\n","    layers.Dense(512, activation='relu', input_shape=input_shape),\n","    layers.Dense(512, activation='relu'),    \n","    layers.Dense(512, activation='relu'),\n","    layers.Dense(1),\n","])\n","model.compile(\n","    optimizer='sgd', # SGD is more sensitive to differences of scale\n","    loss='mae',\n","    metrics=['mae'],\n",")\n","history = model.fit(\n","    X_train, y_train,\n","    validation_data=(X_valid, y_valid),\n","    batch_size=64,\n","    epochs=100,\n","    verbose=0,\n",")\n","\n","history_df = pd.DataFrame(history.history)\n","history_df.loc[0:, ['loss', 'val_loss']].plot()\n","print((\"Minimum Validation Loss: {:0.4f}\").format(history_df['val_loss'].min()))"]},{"cell_type":"markdown","metadata":{},"source":["Jeste li završili s praznim grafikonom? Pokušaj treniranja ove mreže na ovom skupu podataka obično neće uspjeti. Čak i kada konvergira (zbog sretne inicijalizacije težine), ima tendenciju konvergirati na vrlo veliki broj.\n","\n","# 3) Dodajte slojeve normalizacije serije\n","\n","Skupna normalizacija može pomoći u ispravljanju ovakvih problema.\n","\n","Dodajte četiri sloja `BatchNormalization`, jedan prije svakog od gustih slojeva. (Ne zaboravite premjestiti argument `input_shape` na novi prvi sloj.)"]},{"cell_type":"code","execution_count":null,"metadata":{"lines_to_next_cell":0},"outputs":[],"source":["# YOUR CODE HERE: Add a BatchNormalization layer before each Dense layer\n","model = keras.Sequential([\n","    layers.Dense(512, activation='relu', input_shape=input_shape),\n","    layers.Dense(512, activation='relu'),\n","    layers.Dense(512, activation='relu'),\n","    layers.Dense(1),\n","])\n"]},{"cell_type":"markdown","metadata":{},"source":["Pokrenite sljedeću ćeliju da vidite hoće li nam skupna normalizacija omogućiti treniranje modela."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.compile(\n","    optimizer='sgd',\n","    loss='mae',\n","    metrics=['mae'],\n",")\n","EPOCHS = 100\n","history = model.fit(\n","    X_train, y_train,\n","    validation_data=(X_valid, y_valid),\n","    batch_size=64,\n","    epochs=EPOCHS,\n","    verbose=0,\n",")\n","\n","history_df = pd.DataFrame(history.history)\n","history_df.loc[0:, ['loss', 'val_loss']].plot()\n","print((\"Minimum Validation Loss: {:0.4f}\").format(history_df['val_loss'].min()))"]},{"cell_type":"markdown","metadata":{},"source":["# 4) Procijenite normalizaciju serije\n","\n","Je li dodavanje normalizacije serije pomoglo?"]},{"cell_type":"markdown","metadata":{},"source":["# Nastavi #\n","\n","[**Kreiraj neuralnu mežu**](Binary_Classification_hr.ipynb) za binarnu klasifikaciju."]}],"metadata":{"jupytext":{"cell_metadata_filter":"-all","formats":"ipynb"},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":829369,"sourceId":1480608,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
